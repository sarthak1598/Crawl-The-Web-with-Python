# Crawl-The-Web-with-Python


This repository contains the codes written in python for the purpose of  Web scrapping and crawling with some supporting
modules of python.

# Main modules 

1.requests module.
2.urllib module.
3.beautifulsoup(bs4) module.

Basically the purpose of web scrapping is to spider the website or the web applications effectively to retrieve the qualitative and needy information from the web app in faster manner by just using the couple of commands in the termina :)--.


# Brief Description of higly used modules in Web-scraping with python 

 # 1. requests:
 
      This module is used to send the HTTP /1.1 or /1.0 request to the web server/domain.
      This can be used to get http headers in crafted manner as pour requirments.
      Can be used to inspect the initaial level web server security so gives an aid in Pentesting Process.
      
      installation : pip install requests
      
 # 2. urllib:
      urllib module is mainly used for working with Web URLs: urllib.request for opening and reading URL 
      installation : 
      
         ....pip install urllib
      
 # 3. MechanicalSoup:
      This is  one of handy module used in scraping . the speciality of this module is that it can perform interactions like 
      sending and storing cookies and redirections and most important , it can submit forms, can manage links without using any 
      javascript. It can do this tasks in non insteractive manner.
        
      ...pip install MechanicalSoup
      
 # 4. Scrapy:
       Scrapy module can be used to extracting the filtered and required data from the website.
       It can easily manage the user requests and sessions made during the connection. 
       
       ....pip install scrapy 
       
       
 # 5. bs4:
       bs4 module is used to extract data from HTML. 
       This can dissect a document and extract as our requirement. 
       It automatically converts incoming documents to Unicode and outgoing documents to UTF-8.
       
       ....pip install beautifulsoup4
